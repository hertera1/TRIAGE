{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ac30c4e",
   "metadata": {},
   "source": [
    "# Imports & get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be4e6bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../data/communities.data\", header=None, na_values=[\"?\"])\n",
    "from urllib.request import urlopen\n",
    "names = urlopen(\"http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.names\")\n",
    "columns = [line.split(b' ')[1].decode(\"utf-8\") for line in names if line.startswith(b'@attribute')]\n",
    "data.columns = columns\n",
    "data = data.dropna(axis = 1)\n",
    "data = data.iloc[:, 3:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "953f0d8c",
   "metadata": {},
   "source": [
    "## Evaluation helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae3285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_methods(X_prop_train, y_prop_train, X_cal, y_cal, X_test, y_test):\n",
    "    from sklearn.metrics import mean_absolute_error as reg_metric\n",
    "    from sklearn.linear_model import  LinearRegression\n",
    "   \n",
    "    myids = we_group\n",
    "    keep = len(myids)\n",
    "    \n",
    "    #####\n",
    "    print('RESIDUALS DIRECT...')\n",
    "    myids = np.argsort(np.abs(errors_array)[:,-1])[0:keep]\n",
    "    \n",
    "    res_model = xgb.XGBRegressor(n_estimators=nest)\n",
    "    res_model.fit(X_prop_train[myids,:], y_prop_train[myids])\n",
    "\n",
    "    #####\n",
    "    print('INTERVALS DIRECT...')\n",
    "    myids = np.argsort(np.abs(interval_array)[:,-1])[0:keep]\n",
    "    \n",
    "    interval_model = xgb.XGBRegressor(n_estimators=nest)\n",
    "    interval_model.fit(X_prop_train[myids,:], y_prop_train[myids])\n",
    "\n",
    "    ####\n",
    "    print('Actual eval fit...')\n",
    "    cal_model = xgb.XGBRegressor(n_estimators=nest)\n",
    "    cal_model.fit(X_cal, y_cal)\n",
    "\n",
    "    ####\n",
    "    print('MIX fit...')\n",
    "    mix_model = xgb.XGBRegressor(n_estimators=nest)\n",
    "    mix_model.fit(np.vstack((X_prop_train, X_cal)), np.hstack((y_prop_train, y_cal)))\n",
    "\n",
    " \n",
    "    ####\n",
    "    print('Plain...')\n",
    "    plain_model = xgb.XGBRegressor(n_estimators=nest)\n",
    "    plain_model.fit(X_prop_train, y_prop_train)\n",
    "\n",
    "  \n",
    "    ######\n",
    "    print('NGBOOST...')\n",
    "    from ngboost import NGBRegressor\n",
    "    from ngboost.distns import Exponential, Normal, LogNormal\n",
    "\n",
    "    base_learner = LinearRegression()\n",
    "\n",
    "    learner_prop = NGBRegressor(Dist=Normal,\n",
    "                                    Base=base_learner)\n",
    "    learner_prop.fit(X_cal, y_cal)\n",
    "\n",
    "    y_dists = learner_prop.pred_dist(X_prop_train)\n",
    "\n",
    "    uncerts = y_dists[0:].params['scale']\n",
    "\n",
    "    myids = np.argsort(uncerts)[0:keep]\n",
    "\n",
    "    ngboost_model = xgb.XGBRegressor(n_estimators=nest)\n",
    "    ngboost_model.fit(X_prop_train[myids,:], y_prop_train[myids])\n",
    "\n",
    "\n",
    "    ########\n",
    "    print('Bayes ridge...')\n",
    "    from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "    learner_prop = BayesianRidge()\n",
    "\n",
    "    learner_prop.fit(X_cal, y_cal)\n",
    "\n",
    "    y_dists, uncerts = learner_prop.predict(X_prop_train, return_std=True)\n",
    "\n",
    "    myids = np.argsort(uncerts)[0:keep]\n",
    "\n",
    "    ridge_model = xgb.XGBRegressor(n_estimators=nest)\n",
    "    ridge_model.fit(X_prop_train[myids,:], y_prop_train[myids])\n",
    "    \n",
    "    ########\n",
    "    \n",
    "    # import torch\n",
    "\n",
    "    # from uq360.algorithms.variational_bayesian_neural_networks.bnn import BnnRegression\n",
    "\n",
    "    # config = {\n",
    "    #               \"ip_dim\":X_prop_train.shape[1], \n",
    "    #               \"op_dim\":1,                            \n",
    "    #               \"num_nodes\":8, \n",
    "    #               \"num_layers\":5,\n",
    "    #               \"step_size\":3e-2,\n",
    "    #               \"num_epochs\":20,\n",
    "    #           }\n",
    "\n",
    "    # learner_prop = BnnRegression(config = config, prior = 'Gaussian') #, Hshoe, RegHshoe\n",
    "\n",
    "    # learner_prop.fit(torch.Tensor(X_cal), torch.Tensor(y_cal))\n",
    "\n",
    "    # y_dists, lower, upper, _, _ = learner_prop.predict(torch.Tensor(X_prop_train))\n",
    "\n",
    "    # uncerts = upper-lower\n",
    "\n",
    "\n",
    "    # myids = np.argsort(uncerts)[0:keep]\n",
    "\n",
    "    # bnn_model = xgb.XGBRegressor(n_estimators=nest, random_state=seed)\n",
    "    # bnn_model.fit(X_prop_train[myids,:], y_prop_train[myids])\n",
    "\n",
    "\n",
    "    ########\n",
    "    \n",
    "    from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "    gpr = GaussianProcessRegressor(random_state=seed)\n",
    "    gpr.fit(X_cal, y_cal)\n",
    "\n",
    "    y_dists, uncerts = gpr.predict(X_prop_train, return_std=True)\n",
    "\n",
    "    myids = np.argsort(uncerts)[0:keep]\n",
    "\n",
    "    gp_model = xgb.XGBRegressor(n_estimators=nest, random_state=seed)\n",
    "    gp_model.fit(X_prop_train[myids,:], y_prop_train[myids])\n",
    "\n",
    "    # return res_model, interval_model, cal_model, mix_model, plain_model, ngboost_model, ridge_model, bnn_model, gp_model\n",
    "    return res_model, interval_model, cal_model, mix_model, plain_model, ngboost_model, ridge_model,  gp_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e54f0c4",
   "metadata": {},
   "source": [
    "### Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbd8ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from sklearn.metrics import mean_absolute_error as reg_metric\n",
    "import random\n",
    "seed= 589\n",
    "\n",
    "X = data.drop('ViolentCrimesPerPop', axis=1)\n",
    "y = data.ViolentCrimesPerPop\n",
    "\n",
    "cols = X.columns\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "group = 'racepctblack'\n",
    "\n",
    "protected = np.where(X[group] >= 0.5)[0]\n",
    "\n",
    "test_ids_protected = random.sample(list(protected) , int(0.90*len(protected)))\n",
    "\n",
    "priviledged = np.where(X[group] <= 0.5)[0]\n",
    "\n",
    "test_ids_priviledged = random.sample(list(priviledged) , int(0.01*len(priviledged)))\n",
    "\n",
    "test_ids = np.hstack((test_ids_priviledged, test_ids_protected))\n",
    "\n",
    "test_ids = np.array(test_ids)\n",
    "\n",
    "train_ids = np.setdiff1d(range(len(y)), test_ids, assume_unique=True)\n",
    "\n",
    "X_prop_train, y_prop_train = X.iloc[train_ids,:], y.iloc[train_ids]\n",
    "\n",
    "X_eval, y_eval = X.iloc[test_ids,:], y.iloc[test_ids]\n",
    "\n",
    "X_test, X_cal, y_test, y_cal = train_test_split(X_eval, y_eval,\n",
    "                                        test_size=0.15, random_state=seed)\n",
    "\n",
    "X_prop_train, X_cal, X_test = np.array(X_prop_train), np.array(X_cal), np.array(X_test)\n",
    "y_prop_train, y_cal, y_test = np.array(y_prop_train), np.array(y_cal), np.array(y_test)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab939a23",
   "metadata": {},
   "source": [
    "# Computation & sculpting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae8cf835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESIDUALS DIRECT...\n",
      "INTERVALS DIRECT...\n",
      "Actual eval fit...\n",
      "MIX fit...\n",
      "Plain...\n",
      "NGBOOST...\n",
      "[iter 0] loss=0.1805 val_loss=0.0000 scale=2.0000 norm=0.9863\n",
      "[iter 100] loss=-1.0216 val_loss=0.0000 scale=2.0000 norm=0.9479\n",
      "[iter 200] loss=-2.1329 val_loss=0.0000 scale=4.0000 norm=1.9894\n",
      "[iter 300] loss=-4.1329 val_loss=0.0000 scale=4.0000 norm=1.9998\n",
      "[iter 400] loss=-7.9329 val_loss=0.0000 scale=8.0000 norm=4.0000\n",
      "Bayes ridge alea...\n",
      "Bayes ridge...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from fairlearn.reductions import ExponentiatedGradient\n",
    "from fairlearn.reductions import GridSearch \n",
    "from fairlearn.reductions import BoundedGroupLoss, ZeroOneLoss\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from fairlearn.metrics import MetricFrame\n",
    "\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from triage.triage import Triage\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "\n",
    "final_results = []\n",
    "\n",
    "nest = 50\n",
    "learner = xgb.XGBRegressor(n_estimators=nest)\n",
    "learner.fit(X_prop_train, y_prop_train)\n",
    "\n",
    "\n",
    "triage_array = None\n",
    "interval_array = None\n",
    "crps_array = None\n",
    "cpds_array = None\n",
    "errors_array = None\n",
    "\n",
    "test=False\n",
    "\n",
    "\n",
    "y_eval = y_prop_train \n",
    "X_eval = X_prop_train\n",
    "\n",
    "\n",
    "\n",
    "triage = Triage(X_eval = X_eval, y_eval = y_eval, X_cal=X_cal, y_cal=y_cal, nest=nest, learner=learner)\n",
    "groups_ids, raw_metrics = triage.run()\n",
    "    \n",
    "triage_array = raw_metrics['score_metric']\n",
    "errors_array = raw_metrics['errors_array']\n",
    "interval_array = raw_metrics['interval_array']\n",
    "crps_array = raw_metrics['crps_array']\n",
    "cpds_array = raw_metrics['cpds_array']\n",
    "preds_array = raw_metrics['preds_array']\n",
    "upper_array = raw_metrics['upper_array']\n",
    "lower_array = raw_metrics['lower_array']\n",
    "\n",
    "metric = triage_array  \n",
    "percentile_thresh = 75\n",
    "thresh = 0.33\n",
    "conf_thresh_low = thresh\n",
    "conf_thresh_high = 1 - thresh\n",
    "conf_thresh = 0.5\n",
    "\n",
    "uncert= np.mean(metric * (1 - metric), axis=-1)\n",
    "confidence = np.mean(metric, axis=-1)\n",
    "\n",
    "# Get groups and mainly well-estimated groups\n",
    "oe_group = np.where(\n",
    "    (confidence <= conf_thresh_low)\n",
    "    & (uncert<= np.percentile(uncert, percentile_thresh))\n",
    ")[0]\n",
    "ue_group = np.where(\n",
    "    (confidence >= conf_thresh_high)\n",
    "    & (uncert<= np.percentile(uncert, percentile_thresh))\n",
    ")[0]\n",
    "\n",
    "combined_group = np.concatenate((oe_group, ue_group))\n",
    "\n",
    "we_group = []\n",
    "for id in range(len(confidence)):\n",
    "    if id not in combined_group:\n",
    "        we_group.append(id)\n",
    "\n",
    "we_group = np.array(we_group)\n",
    "\n",
    "groups = []\n",
    "for i in range(len(triage_array)):\n",
    "    if i in oe_group:\n",
    "        groups.append(0)\n",
    "    if i in we_group:\n",
    "        groups.append(1)\n",
    "    if i in ue_group:\n",
    "        groups.append(2)\n",
    "        \n",
    "\n",
    "\n",
    "bgl = BoundedGroupLoss(ZeroOneLoss(), upper_bound=0.1)\n",
    "exp_model = ExponentiatedGradient(xgb.XGBRegressor(n_estimators=nest),\n",
    "                   constraints=bgl)\n",
    "exp_model.fit(X_prop_train, y_prop_train, sensitive_features=(y_prop_train >= 0.5).astype(int))\n",
    "\n",
    "\n",
    "bgl = BoundedGroupLoss(ZeroOneLoss(), upper_bound=0.1)\n",
    "\n",
    "sweep = GridSearch(xgb.XGBRegressor(n_estimators=nest),\n",
    "                   constraints=bgl,\n",
    "                   grid_size=3)\n",
    "\n",
    "sweep.fit(X_prop_train, y_prop_train, sensitive_features=(y_prop_train >= 0.5).astype(int))\n",
    "\n",
    "fair0_model = sweep.predictors_[0]\n",
    "fair1_model = sweep.predictors_[1]\n",
    "fair2_model = sweep.predictors_[2]\n",
    "\n",
    "myids = we_group\n",
    "keep = len(myids)\n",
    "learner_prop_triage = xgb.XGBRegressor(n_estimators=nest)\n",
    "learner_prop_triage.fit(X_prop_train[myids,:], y_prop_train[myids])\n",
    "\n",
    "# uncomment to run BNN\n",
    "#res_model, interval_model, cal_model, mix_model, plain_model, ngboost_model, ridge_model, bnn_model, gp_model = evaluate_methods(X_prop_train, y_prop_train, X_cal, y_cal, X_test, y_test)\n",
    "res_model, interval_model, cal_model, mix_model, plain_model, ngboost_model, ridge_model, gp_model = evaluate_methods(X_prop_train, y_prop_train, X_cal, y_cal, X_test, y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0578ec6",
   "metadata": {},
   "source": [
    "# Regression measures for Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30d0d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_regression_measures(y, y_hat, protected, privileged):\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    unique_protected = np.unique(protected)\n",
    "    unique_unprivileged = unique_protected[unique_protected != privileged]\n",
    "\n",
    "    data = pd.DataFrame(columns=['subgroup', 'independence', 'separation', 'sufficiency'])\n",
    "\n",
    "    for unprivileged in unique_unprivileged:\n",
    "        # filter elements\n",
    "        array_elements = np.isin(protected, [privileged, unprivileged])\n",
    "\n",
    "        y_u = ((y[array_elements] - y[array_elements].mean()) / y[array_elements].std()).reshape(-1, 1)\n",
    "        s_u = ((y_hat[array_elements] - y_hat[array_elements].mean()) / y_hat[array_elements].std()).reshape(-1, 1)\n",
    "\n",
    "        a = np.where(protected[array_elements] == privileged, 1, 0)\n",
    "\n",
    "        p_s = LogisticRegression()\n",
    "        p_ys = LogisticRegression()\n",
    "        p_y = LogisticRegression()\n",
    "\n",
    "        p_s.fit(s_u, a)\n",
    "        p_y.fit(y_u, a)\n",
    "        p_ys.fit(np.c_[y_u, s_u], a)\n",
    "\n",
    "        pred_p_s = p_s.predict_proba(s_u.reshape(-1, 1))[:, 1]\n",
    "        pred_p_y = p_y.predict_proba(y_u.reshape(-1, 1))[:, 1]\n",
    "        pred_p_ys = p_ys.predict_proba(np.c_[y_u, s_u])[:, 1]\n",
    "\n",
    "        n = len(a)\n",
    "\n",
    "        r_ind = ((n - a.sum()) / a.sum()) * (pred_p_s / (1 - pred_p_s)).mean()\n",
    "        r_sep = ((pred_p_ys / (1 - pred_p_ys) * (1 - pred_p_y) / pred_p_y)).mean()\n",
    "        r_suf = ((pred_p_ys / (1 - pred_p_ys)) * ((1 - pred_p_s) / pred_p_s)).mean()\n",
    "        \n",
    "        scores = 0\n",
    "        if r_ind>1.25:\n",
    "            scores+=1\n",
    "        if r_sep>1.25:\n",
    "            scores+=1\n",
    "        if r_suf>1.25:\n",
    "            scores+=1\n",
    "            \n",
    "        from sklearn.metrics import mean_squared_error\n",
    "            \n",
    "        mae =  reg_metric(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "        to_append = {'independence': r_ind,\n",
    "                      'separation': r_sep,\n",
    "                      'sufficiency': r_suf,\n",
    "                      'scores': scores,\n",
    "                      'mae': mae,\n",
    "                      'mse': mse,\n",
    "                      'fair': scores<1}\n",
    "    return to_append\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ea0c85e",
   "metadata": {},
   "source": [
    "# Compute results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d6bf409",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pd = pd.DataFrame(X_test, columns=cols)\n",
    "protected = np.where(X_test_pd[group] >= 0.5, 'majority_black', \"else\")\n",
    "privileged = 'else'\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "y_pred = learner.predict(X_test)\n",
    "metrics['base'] = calculate_regression_measures(y=y_test, y_hat=y_pred, protected=protected, privileged=privileged,)\n",
    "\n",
    "y_pred = learner_prop_triage.predict(X_test)\n",
    "metrics['triage'] = calculate_regression_measures(y=y_test, y_hat=y_pred, protected=protected, privileged=privileged,)\n",
    "\n",
    "y_pred = fair0_model.predict(X_test)\n",
    "metrics['fair0_model'] = calculate_regression_measures(y=y_test, y_hat=y_pred, protected=protected, privileged=privileged,)\n",
    "\n",
    "y_pred = fair1_model.predict(X_test)\n",
    "metrics['fair1_model'] = calculate_regression_measures(y=y_test, y_hat=y_pred, protected=protected, privileged=privileged,)\n",
    "\n",
    "y_pred = fair2_model.predict(X_test)\n",
    "metrics['fair2_model'] = calculate_regression_measures(y=y_test, y_hat=y_pred, protected=protected, privileged=privileged,)\n",
    "\n",
    "y_pred = exp_model.predict(X_test)\n",
    "metrics['fair_exp'] = calculate_regression_measures(y=y_test, y_hat=y_pred, protected=protected, privileged=privileged,)\n",
    "\n",
    "y_pred = res_model.predict(X_test)\n",
    "metrics['res_model'] = calculate_regression_measures(y=y_test, y_hat=y_pred, protected=protected, privileged=privileged,)\n",
    "\n",
    "y_pred = interval_model.predict(X_test)\n",
    "metrics['interval_model'] = calculate_regression_measures(y=y_test, y_hat=y_pred, protected=protected, privileged=privileged,)\n",
    "\n",
    "y_pred = cal_model.predict(X_test)\n",
    "metrics['cal_model'] = calculate_regression_measures(y=y_test, y_hat=y_pred, protected=protected, privileged=privileged,)\n",
    "\n",
    "y_pred = mix_model.predict(X_test)\n",
    "metrics['mix_model'] = calculate_regression_measures(y=y_test, y_hat=y_pred, protected=protected, privileged=privileged,)\n",
    "\n",
    "y_pred = plain_model.predict(X_test)\n",
    "metrics['plain_model'] = calculate_regression_measures(y=y_test, y_hat=y_pred, protected=protected, privileged=privileged,)\n",
    "\n",
    "y_pred = ngboost_model.predict(X_test)\n",
    "metrics['ngboost_model'] = calculate_regression_measures(y=y_test, y_hat=y_pred, protected=protected, privileged=privileged,)\n",
    "\n",
    "y_pred = ridge_model.predict(X_test)\n",
    "metrics['ridge_model'] = calculate_regression_measures(y=y_test, y_hat=y_pred, protected=protected, privileged=privileged,)\n",
    "\n",
    "# y_pred = bnn_model.predict(X_test)\n",
    "# metrics['bnn_model'] = calculate_regression_measures(y=y_test, y_hat=y_pred, protected=protected, privileged=privileged,)\n",
    "\n",
    "y_pred = gp_model.predict(X_test)\n",
    "metrics['gp_model'] = calculate_regression_measures(y=y_test, y_hat=y_pred, protected=protected, privileged=privileged,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90633691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>independence</th>\n",
       "      <th>separation</th>\n",
       "      <th>sufficiency</th>\n",
       "      <th>scores</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>fair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>1.291645</td>\n",
       "      <td>1.178324</td>\n",
       "      <td>1.009437</td>\n",
       "      <td>1</td>\n",
       "      <td>0.18411</td>\n",
       "      <td>0.055423</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triage</th>\n",
       "      <td>1.209842</td>\n",
       "      <td>1.112505</td>\n",
       "      <td>1.003123</td>\n",
       "      <td>0</td>\n",
       "      <td>0.177235</td>\n",
       "      <td>0.052826</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fair0_model</th>\n",
       "      <td>1.010078</td>\n",
       "      <td>0.998461</td>\n",
       "      <td>1.017691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.295557</td>\n",
       "      <td>0.125423</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fair1_model</th>\n",
       "      <td>1.214557</td>\n",
       "      <td>1.117667</td>\n",
       "      <td>0.99944</td>\n",
       "      <td>0</td>\n",
       "      <td>0.19306</td>\n",
       "      <td>0.060235</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fair2_model</th>\n",
       "      <td>1.307011</td>\n",
       "      <td>1.164173</td>\n",
       "      <td>0.998121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255597</td>\n",
       "      <td>0.110098</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fair_exp</th>\n",
       "      <td>1.291645</td>\n",
       "      <td>1.178324</td>\n",
       "      <td>1.009437</td>\n",
       "      <td>1</td>\n",
       "      <td>0.18411</td>\n",
       "      <td>0.055423</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>res_model</th>\n",
       "      <td>1.405469</td>\n",
       "      <td>1.194699</td>\n",
       "      <td>1.034667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.174659</td>\n",
       "      <td>0.050284</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interval_model</th>\n",
       "      <td>1.258044</td>\n",
       "      <td>1.147145</td>\n",
       "      <td>1.0143</td>\n",
       "      <td>1</td>\n",
       "      <td>0.171621</td>\n",
       "      <td>0.046789</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cal_model</th>\n",
       "      <td>1.141745</td>\n",
       "      <td>1.08543</td>\n",
       "      <td>0.993856</td>\n",
       "      <td>0</td>\n",
       "      <td>0.217411</td>\n",
       "      <td>0.068866</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mix_model</th>\n",
       "      <td>1.268938</td>\n",
       "      <td>1.132202</td>\n",
       "      <td>1.021178</td>\n",
       "      <td>1</td>\n",
       "      <td>0.170751</td>\n",
       "      <td>0.046694</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plain_model</th>\n",
       "      <td>1.291645</td>\n",
       "      <td>1.178324</td>\n",
       "      <td>1.009437</td>\n",
       "      <td>1</td>\n",
       "      <td>0.18411</td>\n",
       "      <td>0.055423</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ngboost_model</th>\n",
       "      <td>1.472248</td>\n",
       "      <td>1.266349</td>\n",
       "      <td>1.021356</td>\n",
       "      <td>2</td>\n",
       "      <td>0.19585</td>\n",
       "      <td>0.059409</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge_model</th>\n",
       "      <td>1.390985</td>\n",
       "      <td>1.213804</td>\n",
       "      <td>1.004332</td>\n",
       "      <td>1</td>\n",
       "      <td>0.191257</td>\n",
       "      <td>0.057875</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gp_model</th>\n",
       "      <td>1.43349</td>\n",
       "      <td>1.288388</td>\n",
       "      <td>1.021078</td>\n",
       "      <td>2</td>\n",
       "      <td>0.188678</td>\n",
       "      <td>0.05592</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               independence separation sufficiency scores       mae       mse  \\\n",
       "base               1.291645   1.178324    1.009437      1   0.18411  0.055423   \n",
       "triage             1.209842   1.112505    1.003123      0  0.177235  0.052826   \n",
       "fair0_model        1.010078   0.998461    1.017691      0  0.295557  0.125423   \n",
       "fair1_model        1.214557   1.117667     0.99944      0   0.19306  0.060235   \n",
       "fair2_model        1.307011   1.164173    0.998121      1  0.255597  0.110098   \n",
       "fair_exp           1.291645   1.178324    1.009437      1   0.18411  0.055423   \n",
       "res_model          1.405469   1.194699    1.034667      1  0.174659  0.050284   \n",
       "interval_model     1.258044   1.147145      1.0143      1  0.171621  0.046789   \n",
       "cal_model          1.141745    1.08543    0.993856      0  0.217411  0.068866   \n",
       "mix_model          1.268938   1.132202    1.021178      1  0.170751  0.046694   \n",
       "plain_model        1.291645   1.178324    1.009437      1   0.18411  0.055423   \n",
       "ngboost_model      1.472248   1.266349    1.021356      2   0.19585  0.059409   \n",
       "ridge_model        1.390985   1.213804    1.004332      1  0.191257  0.057875   \n",
       "gp_model            1.43349   1.288388    1.021078      2  0.188678   0.05592   \n",
       "\n",
       "                 fair  \n",
       "base            False  \n",
       "triage           True  \n",
       "fair0_model      True  \n",
       "fair1_model      True  \n",
       "fair2_model     False  \n",
       "fair_exp        False  \n",
       "res_model       False  \n",
       "interval_model  False  \n",
       "cal_model        True  \n",
       "mix_model       False  \n",
       "plain_model     False  \n",
       "ngboost_model   False  \n",
       "ridge_model     False  \n",
       "gp_model        False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = pd.DataFrame.from_dict(metrics)\n",
    "\n",
    "my_df = my_df.T\n",
    "\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86923619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env_triage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
